# Mixing Polly voice with an audio clip
A couple of weeks ago [Daniel Mittendorf](https://twitter.com/DanMittendorf) published a [project](https://twitter.com/DanMittendorf/status/1115530355673579520) in which he described how to mix Polly voices with a background audio using NodeJS. I decided to do the same in Python using the ASK SDK for Python. That is the reason of this article. 

Thank you very much Daniel for the inspiration.

# What can you expect from this article?
An understanding of how to mix Polly voices with an audio clip as background.

# Requirements 
- An account at the AWS Console. Allows us to use Lambda, S3, and so on.
- An account at the Alexa Developers Portal. Allows us to create Skills.
- Basic command-line knowledge.
- Some audio clips/track to use.

# About AWS Polly
## What is it?
AWS Polly is a service that allows us to convert text to speech (TTS).

## Pricing
Like most (all) AWS services it has e free tier that allows us to convert up to 5M characters or requests a month for a year starting from the first request. Additionally, offers 1M characters or requests of conversion a month for $4 after the free tier.

For example, you can send 1000 requests of 1000 characters each, that will be $4.

The letter that Jeff Bezos sent to the stakeholders this year that is about 15.500 characters long will be like $0,006.

## Voices
Currently there are 57 voices in a total of 28 languages available. In Spanish (Spain) there are 3:

**Conchita:** I think she is a mature woman, probably around 50 years old. I think she is a great voice for storytelling, short stories, advice to mums and also a news briefing.

**Lucía:** Is notably younger compared to Conchita. I would say she is probably between 28 and 40 years old. She is a great voice for events publicity or announcements, art events and even cosmetics.

**Enrique:** He is, probably, between 38 and 45 years old. Great voice for news, sports events or announcements.

**Important**: The audio stream generated by AWS Polly has a default sample rate of 22050Hz. Also 8000Hz and 16000Hz are available. This is very important because when mixing both audio streams have to have the same sample rate otherwise *sox* will fail.

# Where can you get audio files to use in your Skill?
[Here](https://medium.com/r/?url=https%3A%2F%2Fbuffer.com%2Flibrary%2Fbackground-music-video) you can find a list of sites where you can get audio files to use in your Skill.

## Brief comments on licenses
There are, basically, 3 type of licenses.

- **Royalty Free:** These licences allow us to use the copyrighted content freely without the permission (authorization, consent) of the author without having to pay royalties per reproduction however a one-time payment might be required.
- **Public Domain:** These licences allow us to use the content that is not protected by copyright without having to pay to or requiring permission from the author. This basically means that one can copy, distribute, interpret and display publicly the content like it belongs to everyone.
- **Creative Commons:** It is a set of licences that apply to any type of content from images to audio. Allow us the distribution of copyrighted content for free as long as the author (original) receives the appropriate attribution.

# SSML: *audio* tag
When developing a Skill, Alexa service takes care of the TTS including an appropriate pause after punctuation signs, using the right tone when asking a question and so on.

The Voice Browser Working Group at W3C, as part of the W3C Voice Browser Activity, created a set of standards to access the web with voice interactions, one of those standards is the Speech Synthesis Markup Language (SSML). SSML is basically rich XML-based. Includes tags that are specific tags to generate synthetic speech on the web and other applications. With SSML one can control different aspects of the speech such as pitch, speed, rate or volume and so on.

In this article I describe specifically the *audio* tag.

The *audio* tag tells Alexa service to reproduce an audio file when rendering the response to the user. This audio file can be a pre-recorded sound effect or just background music. 

This tag can be included at any point of the responde, like in between other phrases. For example:

```xml
<speak>
    Bienvenidos a Pumped Crossfit. 
    <audio src="https://s3-eu-west-1.amazonaws.com/mixedpolly/hip_hop_sample.mp3" /> 
    Te ofrecemos información sobre nuestros WODs y tus clases.
</speak>
```

In the example above, Alexa welcomes the user and plays an audio file and then tells the user what can be done.

## There are a few important things to take into account
- Up to 5 audio file can be included in one response.
- The maximum duration is 240 seconds in total.
- The supported format is MP3.
- The files have to be available through HTTPS and should be available publicly.
- Self-signed SSL certificates are not allowed.
- The bit rate should be 48kbps.
- The sample rate can be 16000Hz, 22050Hz or 24000Hz.
- No sensitive information is to be included in the audio.
- No authentication is needed to access the files.
- It is recommended the files are hosted in a server close enough (within the same region, for example) to where the Skill is hosted.
- It is possible to use HLS (HTTP Live Stream) however taking into account the 240 seconds limitation, it might not be a good a idea.
- If you decide to host the audio files using S3 then remember to give your Lambda user permissions to access the S3 service.

# Tools
In most cases, a re-codification of the audio file is needed to comply with the sample rate, for example. I would suggest using Audacity, SoX or FFmpeg. Take a look the [Amazon’s documentation](https://medium.com/r/?url=https%3A%2F%2Fdeveloper.amazon.com%2Fes%2Fdocs%2Fcustom-skills%2Fspeech-synthesis-markup-language-ssml-reference.html%23audio) about this.

In this article I am going to use SoX. As it is the tool available to be used in Lambda and also Daniel made the effort to provide it, reusability is king! (Thanks again Daniel).

It is very important to remember that both Polly audio streams and the audio file’s sample rate should be the same in order to be combined by SoX. This is, both should be 22050Hz, as it is the highest quality available at the moment.

# Classic Skill Intro: Goal, structure, packages
## Goal
The Skill I propose as example will welcome the user and then asks for a person’s name, depending on the gender the Skills thinks the person is will use one or another voice. In this case will use Lucía’s or Enrique’s.

## Structure
The Skill has the following requests and intents:
```
LaunchRequest
HelpIntent
CancelOrStopIntent
FallbackIntent
SessionEndedRequest
CatchAllException
HelloWorldIntent
```

Basically the way the Skill works is:
- The Skill starts welcoming the user, using Lucía’s voice with some music in the background (*LaunchRequest*).
- Right after will ask for a person’s name and depending on the gender the Skill guesses it will continue using Lucía’s voice or change to Enrique´s in case the gender is male (*HelloWorldIntent*).
- The session closes.

# Additional packages
There are some Python packages that we will use.
- **boto3 (comes with the ask-sdk):** Used to create the S3 and Polly clients.
- **subprocess:** Used to perform the tasks related to the environment like copying files.
- **hashlib:** used to calculate the *md5* of the resulting audio file to be used as the filename in S3.
- **mutagen: **Used to calculate the audio file length in seconds.
- **gender_guesser:** Used to guess the gender of the person’s name provided by the user.

# How the Skill works
The sample skill is available [here](https://medium.com/r/?url=https%3A%2F%2Fgithub.com%2Ffrivas%2Falexa-mixed-polly). Take a look at *hello_world.py* - not the most original name ever :)-.

The first thing we to think of is the availability of the tool that will be used to combine the audio streams (Polly and background music).

I have placed the *sox* tool in the *audio* directory (Thanks again Daniel). As the environment where our Lambda function is executed is read-only there is a need to create a functions that copies the tool to a directory where its permissions can be changed and then executed. That directory is */tmp*. For that reason *prepareTools()*:

```python
def prepareTools():
    exists = os.path.isfile('/tmp/sox')
    if not exists:
        logger.info('FILE DOES NOT EXISTS')
        cp_cmd_output = subprocess.run([f"cp {os.environ['LAMBDA_TASK_ROOT']}/audio/sox /tmp; chmod 755 /tmp/sox"], shell=True, stderr=subprocess.STDOUT, stdout=subprocess.PIPE)
        logger.info(f"CP {cp_cmd_output}")
```

What this function does is check the existence of *sox* tool and if it does not exist it will copy it from *audio* directory to */tmp* and change its permissions so it can be executed.

Then there are some variables needed:
```python
my_region = 'eu-west-1'
bucket_name = '<bucket_name>'
polly_url = f'https://polly.{my_region}.amazonaws.com/'
s3_url = f'https://s3-{my_region}.amazonaws.com/'
background_file_intro = f"{os.environ['LAMBDA_TASK_ROOT']}/audio/pavane_aws.mp3"
hello_file = f"{os.environ['LAMBDA_TASK_ROOT']}/audio/inspirational_aws.mp3"
```

- **my_region:** First of all the region where you have your Skill and S3 bucket, it is recommended they are in the same region.
- **bucket_name:** The name of the bucket where the audio files will be stored.
- **polly_url:** The URL of the Polly service.
- **s3_url:** The URL of the bucket that will be used to store the mixed audio file. It does not have to be S3 however for the sake of simplicity and the series of benefits, S3 is the best choice at least you prefer something else.
- **background_file_into:** Path to the audio file that you want to use. It can be an array of filenames concatenated with the path as well, for example. It is very important to mention the Lambda function that the environment our Lambda function is located is read-only, */tmp* is available to be used as temporary space for storage, for example. Also this path can be accessed through the environment variable called *LAMBDA_TASK_ROOT* this is */var/task* that is why the Skill gets the tool from the *audio* directory.

Next, is the function that will return a Polly client object that later will be used to access the synthesis speech method.

```python
def connectToPolly(regionName=my_region, endpointUrl=polly_url):
    return boto3.client('polly', region_name=regionName, endpoint_url=endpointUrl)
```

Now, here comes the magic

The following function firstly, uses synthesis speech method of Polly and providing the required information such as *format, text* and *voice*, returns a stream of bytes that later are written to a file locally.

Then this file is taken and parsed to get its length (duration) in seconds. This information will be used later.

Finally, a command that performs the magic: sox.

- **/tmp/sox**: SoX is the Swiss Army knife of sound processing programs.
- **-m {backgroundSFX} /tmp/sound.mp3**: tells SoX to combine the following 2 files.
- **-C 48.01**: indicates the compression, it varies depending on the file format. The suggested value is 48.01.
- **/tmp/output.mp3**: it is the path and filename were SoX will write the combined stream of bytes.
- **rate 22050**: this sets the sample rate of the combined file. As mentioned before 22050Hz is used because that is the default and highest sample rate Polly supports.
- **gain -l 16**: indicates the increase (if the value is positive) or decrease (if the value is negative) of power measure in dBs. In this particular case *-l 16* flag indicates a limitation to 16 dB without clipping. I think *compand* is worth a try.
- **trim 0 {audio_length + 4}**: indicates SoX to trim the combined audio file to the length of the audio from Polly + 4 seconds. The added seconds is just to avoid abrupt cuts. One might even add *face out*.

The command is executed and the *returncode* from that execution is returned. This can be used to verify the success or failure of the command.

```python
def generatePollyMix(polly, text, voice, backgroundSFX, format='mp3'):
    resp = polly.synthesize_speech(OutputFormat=format, Text=text, VoiceId=voice)
    soundfile = open(f"/tmp/sound.mp3", 'wb')
    soundBytes = resp['AudioStream'].read()
    soundfile.write(soundBytes)
    soundfile.close()

    audio = MP3("/tmp/sound.mp3")
    audio_length = audio.info.length

    sox_cmd = f"/tmp/sox -m {backgroundSFX} /tmp/sound.mp3 -C 48.01 /tmp/output.mp3 rate 22050 gain -l 16 trim 0 {audio_length + 4}"

    sox_cmd_output = subprocess.run([sox_cmd], shell=True, stderr=subprocess.STDOUT, stdout=subprocess.PIPE)

    return sox_cmd_output.returncode
```

The next function will calculate the *md5* of the combined file, upload it to the specified bucket, set the appropriate permissions, remove the unnecessary files and create the SSML’s audio tag to be used in Alexa’s response.

```python
def getS3AudioFile():
    s3_filename = hashlib.md5(open('/tmp/output.mp3', 'rb').read()).hexdigest() + '.mp3'
    s3.Bucket(bucket_name).upload_file(Filename='/tmp/output.mp3', Key=s3_filename, ExtraArgs={'ACL':'public-read'})

    os.remove('/tmp/sound.mp3')
    os.remove('/tmp/output.mp3')
    return f'<audio src="{s3_url}{bucket_name}/{s3_filename}"/>'
```

# How the Sample Skill works
## LaunchRequest

First a Polly object (client) is created by calling the appropriate function *connectToPolly()*.

Then the magic function is called *generatePollyMix* with the appropriate parameters. In this case Lucía’s voice is used.

Right after the combined file is uploaded to S3, the URL returned is used in Alexa’s final response.

Alexa waits for the user to provide a person’s name.

```python
    def handle(self, handler_input):
        # type: (HandlerInput) -> Response
        prepareTools()

        polly = connectToPolly()

        polly_mix_result = generatePollyMix(polly, "Hola, bienvenidos a esta skill de ejemplo. Prueba decirme nombres de chico y chica y eso determinará la voz que utilizaré", 'Lucia', background_file_intro)

        audio_mix = getS3AudioFile()

        speech_text = f"<speak> Esto es Poly {audio_mix} Dime un numbre</speak>"
        logger.info(speech_text)
        logger.info(get_plain_text_content(primary_text=speech_text))
        handler_input.response_builder.speak(speech_text).set_should_end_session(False)
        return handler_input.response_builder.response
```

## HelloWorldIntent

As mentioned before the user is required to provide a person’s name, once the user provides it, the *HelloWolrdIntent* is executed. 

After creating a Polly object, a *gender_detector* is created that is used to guess the gender of the person which name was provided. The idea is change the used Polly’s voice to the guessed gender, so if gender is female Polly’s voice will be Lucía’s else it will be Enrique’s.

In this intent the new helper function called *get_slot_value* from *ask_sdk_core.utils.request_util* package is used. This is one of the latests additions to the SDK. More information [here](https://medium.com/r/?url=https%3A%2F%2Fgithub.com%2Falexa%2Falexa-skills-kit-sdk-for-python%2Fblob%2Fmaster%2Fask-sdk-core%2Fask_sdk_core%2Futils%2Frequest_util.py) and [here](https://medium.com/r/?url=https%3A%2F%2Falexa-skills-kit-python-sdk.readthedocs.io%2Fen%2Flatest%2Fapi%2Fcore.html%3Fhighlight%3Dget_slot_value%23ask_sdk_core.utils.request_util.get_slot_value).

The rest is the same as the *LaunchRequest*.

```python
    def handle(self, handler_input):
        # type: (HandlerInput) -> Response
        polly = connectToPolly()

        gender_detector = gender.Detector()

        get_name = get_slot_value(handler_input, 'name')
        logger.info(f"NAME {get_name}")

        get_gender = gender_detector.get_gender(get_name.capitalize())
        logger.info(f"GENDER {get_gender}")

        polly_mixed_result = generatePollyMix(polly, f"usar Poly en tu Skill te permite ofrecer una experiencia única.", 'Enrique' if get_gender == 'male' else 'Lucia', hello_file)

        audio_mix = getS3AudioFile()

        speech_text = f"<speak>{get_name.capitalize()}, {audio_mix}</speak>"
        handler_input.response_builder.speak(speech_text).set_should_end_session(True)
        return handler_input.response_builder.response
```

# Final notes
- It is important being precise with the volume of each audio file. You can use Audacity to modify the files before using them. Take a look at the [documentation](https://medium.com/r/?url=https%3A%2F%2Fdeveloper.amazon.com%2Fes%2Fdocs%2Fflashbriefing%2Fnormalizing-the-loudness-of-audio-content.html) provided by Amazon about this.
- You can add *fade in* and *fade out* effects to the audio files so the experience in the transition to Alexa’s voice is smoother. There is no abrupt cuts.
- I have observed that sometimes with some music genres like Hip-Hop, Polly’s voice barely can be heard. Probably changing the gain.
- Use the Voice & Tone tab from the simulator at the Alexa Developer’s Portal.
- It would be good to verify the return code from the *subprocess* execution assure a good error handling and alternatives to failure. If there is any issue and want to see what is going on just remove *.returncode*.

# In this article
- I have, briefly, described AWS Polly.
- Also described SSML and its *audio* tag, some tools to handle audio files.
- Described the sample Skill. Pay special attention to *LaunchRequest*, *HelloWorldIntent* and the function *generatePollyMix*.

# References
- [W3X SSML Standard](https://medium.com/r/?url=https%3A%2F%2Fwww.w3.org%2FTR%2F2003%2FCR-speech-synthesis-20031218%2F).
- [SSML’s Amazon Specifications](https://medium.com/r/?url=https%3A%2F%2Fdeveloper.amazon.com%2Fes%2Fdocs%2Fcustom-skills%2Fspeech-synthesis-markup-language-ssml-reference.html).
- [Example Skill’s code](https://medium.com/r/?url=https%3A%2F%2Fgithub.com%2Ffrivas%2Falexa-mixed-polly).
- [Daniel Mittendorf’s project](https://medium.com/r/?url=https%3A%2F%2Fgithub.com%2FDanMittendorf%2Falexa-polly-background-mixing-nodejs).

## If there are any issues with the code or you want to provide suggestions, comments or get in touch, do not hesitate. 
